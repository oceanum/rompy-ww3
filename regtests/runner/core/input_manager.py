"""Input file management for WW3 regression tests.

This module provides functionality to download input files from the NOAA WW3 repository.
"""

import json
import logging
from pathlib import Path
from typing import List, Set, Optional, Dict
from urllib.request import urlopen
from urllib.error import HTTPError, URLError
import yaml


logger = logging.getLogger(__name__)


# Base URLs for NOAA WW3 repository
NOAA_WW3_RAW_URL = "https://raw.githubusercontent.com/NOAA-EMC/WW3/develop/regtests"
NOAA_WW3_API_URL = "https://api.github.com/repos/NOAA-EMC/WW3/contents/regtests"

# Files to skip - these are configuration files that rompy generates as .nml
SKIP_EXTENSIONS = {".nml", ".inp"}


class InputFileManager:
    """Manages input file discovery and downloading for WW3 tests.

    This class handles downloading static input files from NOAA WW3 repository.
    Configuration files (.nml, .inp) are NOT downloaded - they are compared
    remotely by the NamelistComparator or generated by rompy.

    Example:
        >>> manager = InputFileManager()
        >>> test_case = TestCase(config_path="regtests/ww3_tp2.4/rompy_ww3_tp2_4.yaml")
        >>> manager.download_all_inputs(test_case)
    """

    def __init__(
        self,
        base_url: str = NOAA_WW3_RAW_URL,
        api_url: str = NOAA_WW3_API_URL,
    ):
        """Initialize input file manager.

        Args:
            base_url: Base URL for NOAA WW3 raw files
            api_url: GitHub API URL for listing directory contents
        """
        self.base_url = base_url
        self.api_url = api_url

    def list_input_directory(self, test_name: str) -> List[Dict]:
        """List all files in the input directory from NOAA repository.

        Args:
            test_name: Name of the test (e.g., "ww3_tp1.1", "mww3_test_01")

        Returns:
            List of file info dictionaries from GitHub API
        """
        url = f"{self.api_url}/{test_name}/input?ref=develop"

        try:
            logger.debug(f"Listing input directory: {url}")
            with urlopen(url, timeout=30) as response:
                data = json.loads(response.read().decode("utf-8"))

            files = [item for item in data if item.get("type") == "file"]
            logger.debug(f"Found {len(files)} files in {test_name}/input")
            return files

        except HTTPError as e:
            if e.code == 404:
                logger.warning(f"No input directory found for {test_name}")
                return []
            logger.error(f"HTTP error listing input directory: {e.code}")
            return []
        except Exception as e:
            logger.error(f"Error listing input directory: {e}")
            return []

    def download_file(self, url: str, dest_path: Path) -> bool:
        """Download a single file from URL.

        Args:
            url: URL to download from
            dest_path: Destination path for the file

        Returns:
            True if successful, False otherwise
        """
        try:
            logger.debug(f"Downloading {url} -> {dest_path}")
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            with urlopen(url, timeout=60) as response:
                dest_path.write_bytes(response.read())
            logger.debug(f"Successfully downloaded {dest_path.name}")
            return True
        except HTTPError as e:
            logger.error(f"HTTP error downloading {url}: {e.code}")
            return False
        except URLError as e:
            logger.error(f"URL error downloading {url}: {e.reason}")
            return False
        except Exception as e:
            logger.error(f"Error downloading {url}: {e}")
            return False

    def download_all_inputs(
        self, test_case, dry_run: bool = False
    ) -> Dict[str, List[str]]:
        """Download static input files for a test case from NOAA repository.

        Downloads static data files needed to run the model (grids, points, etc.).
        Configuration files (.nml, .inp) are skipped - rompy generates .nml files
        and .inp files are compared remotely or not needed.

        Args:
            test_case: TestCase instance
            dry_run: If True, only report what would be downloaded

        Returns:
            Dictionary with 'downloaded', 'failed', 'skipped', and 'existing' lists
        """
        results = {"downloaded": [], "failed": [], "skipped": [], "existing": []}

        test_name = test_case.name
        if not test_name.startswith("ww3_") and not test_name.startswith("mww3_"):
            test_name = f"ww3_{test_name}"

        files = self.list_input_directory(test_name)

        if not files:
            logger.info(f"No input files to download for {test_case.name}")
            return results

        # Filter out configuration files (.nml, .inp) - rompy generates these
        static_files = [
            f for f in files 
            if not any(f["name"].endswith(ext) for ext in SKIP_EXTENSIONS)
        ]
        config_files = [
            f for f in files 
            if any(f["name"].endswith(ext) for ext in SKIP_EXTENSIONS)
        ]

        logger.info(
            f"Input directory for {test_case.name}: "
            f"{len(static_files)} static files to download, "
            f"{len(config_files)} config files (rompy generates .nml)"
        )

        for file_info in static_files:
            file_name = file_info["name"]
            download_url = file_info["download_url"]
            local_path = test_case.test_dir / "input" / file_name

            if local_path.exists():
                results["existing"].append(str(local_path))
                continue

            if dry_run:
                results["skipped"].append(str(local_path))
                continue

            if self.download_file(download_url, local_path):
                results["downloaded"].append(str(local_path))
            else:
                results["failed"].append(str(local_path))

        logger.info(
            f"Static inputs for {test_case.name}: "
            f"{len(results['downloaded'])} downloaded, "
            f"{len(results['existing'])} existing, "
            f"{len(results['failed'])} failed"
        )

        return results

    def ensure_all_inputs(self, test_case, dry_run: bool = False) -> bool:
        """Ensure all static input files are available for a test case.

        Args:
            test_case: TestCase instance
            dry_run: If True, only report what would be downloaded

        Returns:
            True if all inputs are available, False otherwise
        """
        results = self.download_all_inputs(test_case, dry_run=dry_run)

        if results["failed"]:
            logger.error(
                f"Failed to download {len(results['failed'])} files for {test_case.name}"
            )
            return False

        return True

    # Legacy methods for backward compatibility
    def extract_input_references(self, config: dict) -> Set[str]:
        """Extract input file paths from YAML configuration (legacy)."""
        input_files = set()

        def _scan_value(value):
            if isinstance(value, dict):
                if value.get("model_type") in ("data_blob", "data_link"):
                    source = value.get("source")
                    if source and isinstance(source, str):
                        if "input/" in source or source.endswith(".dat") or source.endswith(".list"):
                            input_files.add(source)
                for k, v in value.items():
                    _scan_value(v)
            elif isinstance(value, list):
                for item in value:
                    _scan_value(item)

        _scan_value(config)
        return input_files

    def get_required_inputs(self, test_case) -> List[Path]:
        """Get list of required input files (legacy)."""
        try:
            config = test_case.load_config()
        except Exception as e:
            logger.warning(f"Could not load config for {test_case.name}: {e}")
            return []

        input_refs = self.extract_input_references(config)
        input_files = []
        for ref in input_refs:
            if ref.startswith("regtests/"):
                path = Path(ref)
            elif ref.startswith("/"):
                path = Path(ref)
            else:
                path = test_case.test_dir / ref
            input_files.append(path)

        return input_files

    def get_missing_inputs(self, test_case) -> List[Path]:
        """Check which required input files are missing (legacy)."""
        required = self.get_required_inputs(test_case)
        missing = [p for p in required if not p.exists()]
        return missing

    def download_inputs(self, test_case, dry_run: bool = False) -> dict:
        """Download missing input files (legacy - redirects to download_all_inputs)."""
        return self.download_all_inputs(test_case, dry_run=dry_run)

    def ensure_inputs(self, test_case, dry_run: bool = False) -> bool:
        """Ensure all input files are available (legacy - redirects to ensure_all_inputs)."""
        return self.ensure_all_inputs(test_case, dry_run=dry_run)
